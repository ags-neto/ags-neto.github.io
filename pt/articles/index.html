<!DOCTYPE html>
<html lang="pt">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Publicações de André Neto.">
    <meta name="author" content="André Neto">

    <title>André Neto</title>
    <link rel="icon" type="image/png" href="../../favicon.png">
    <link rel="stylesheet" href="../../assets/main.css">

    <script src="../../assets/js/date-manager.js" defer></script>
</head>

<body>
    <header>
        <nav class="navbar container">

            <p><a href="../">André Neto</a></p>

			<p><a href="../about/">Sobre mim</a></p>
            <h3>Artigos</h3>

			<p><a href="../../en/articles/">English</a></p>

		</nav>
    </header>

    <main class="container">
        <h1>Artigos Publicados</h1>

        <section class="publication-list">
            <article class="publication-item">
                <h2>Pseudo-MOS Learning: A Hybrid Full-to-No-Reference FIQA Framework</h2>
                <p><strong>Autores:</strong> André Neto, Nuno Gonçalves</p>
                <p><strong>Publicado em:</strong> IbPRIA 2025 &mdash; 12ª Conferência Ibérica sobre Reconhecimento de Padrões e Análise de Imagem</p>
                <p><strong>Resumo:</strong> Existe uma discrepância persistente entre as métricas padrão de Avaliação da Qualidade de Imagem (IQA) e os julgamentos perceptivos humanos, geralmente quantificados através de Mean Opinion Scores (MOS). Esta lacuna representa um desafio crítico para tarefas onde a qualidade visual impacta diretamente o desempenho, como é o caso do reconhecimento facial e da transmissão de dados visuais. Em particular, a avaliação da qualidade perceptiva de imagens faciais distorcidas por esteganografia continua a ser difícil, especialmente na ausência de imagens de referência. Para enfrentar este problema, propomos uma framework híbrida de Avaliação da Qualidade de Imagem Facial (FIQA), que transita do modelo com referência total para o modelo sem referência, baseada numa estratégia de aprendizagem orientada por pseudo-MOS. Primeiramente, é treinada uma métrica de fusão full-reference, através da regressão de múltiplas métricas clássicas de IQA com base nos valores MOS humanos, numa subamostra de um conjunto de dados faciais. Esta métrica é então aplicada ao conjunto completo para gerar rótulos pseudo-MOS. Utilizando deep features extraídas de um modelo ResNet-18 pré-treinado no ImageNet, treinamos um regressor no-reference capaz de prever a qualidade perceptiva. A framework proposta liga a supervisão full-reference à inferência no-reference, oferecendo uma solução escalável e precisa para FIQA em condições desafiantes, abrindo caminho para concepções de IQA orientadas por dados e específicas para cada aplicação.
                </p>

                <div class="publication-actions">
                    <a href="../../assets/articles/ibpria2025.pdf" class="button" target="_blank" >Ler artigo</a>
                    <a href="../../assets/articles/ibpria2025.pdf" download class="button">Descarregar PDF</a>
                </div>
            </article>

            <!-- Mais artigos aqui -->
        </section>
    </main>

    <footer class="site-footer container">
        <hr>
        <p>&copy; <span id="copyright"></span> André Neto</p>
        <a href="mailto:email@ags-neto.com">email@ags-neto.com</a>
    </footer>

    <script>
        async function fetchCitations(doi, elementId) {
            try {
                const res = await fetch(`https://api.semanticscholar.org/graph/v1/paper/${doi}?fields=citationCount`);
                const data = await res.json();
                document.getElementById(elementId).textContent = data.citationCount || '0';
            } catch (e) {
                document.getElementById(elementId).textContent = 'N/D';
            }
        }

        fetchCitations('DOI_DO_ARTIGO_AQUI', 'citations-artigo-1');
    </script>
</body>

</html>
