<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="André Neto's Publications.">
    <meta name="author" content="André Neto">

    <title>André Neto</title>
    <link rel="icon" type="image/png" href="../../favicon.png">
    <link rel="stylesheet" href="../../assets/main.css">

    <script src="../../assets/js/date-manager.js" defer></script>
</head>

<body>
    <header>
        <nav class="navbar container">

            <p><a href="../">André Neto</a></p>

			<p><a href="../about">About me</a></p>
            <h3>Articles</h3>

			<p><a href="../../pt/articles/">Português</a></p>

		</nav>
    </header>

    <main class="container">
        <h1>Published Articles</h1>

        <section class="publication-list">
            <article class="publication-item">
                <h2>Pseudo-MOS Learning: A Hybrid Full-to-No-Reference FIQA Framework</h2>
                <p><strong>Authors:</strong> André Neto, Nuno Gonçalves</p>
                <p><strong>Published in:</strong> IbPRIA, 2025</p>
                <p><strong>Abstract:</strong> A persistent discrepancy exists between standard Image Quality Assessment (IQA) metrics and human perceptual judgments, typically quantified through Mean Opinion Scores (MOS).
                    This gap poses a critical challenge for tasks where visual quality directly impacts performance, such as facial recognition and visual data transmission.
                    In particular, assessing the perceptual quality of steganographically distorted facial images remains difficult, especially in the absence of reference images.
                    To address this, we introduce a hybrid Full-to-No-Reference framework for Face Image Quality Assessment (FIQA), built upon a learning strategy based on pseudo-MOS.
                    A full-reference fusion metric is first trained by regressing multiple classical IQA scores against human MOS on a subset of a facial dataset.
                    This metric is then applied to the full dataset to generate pseudo-MOS labels.
                    Using deep features extracted from a ResNet-18 model pretrained on ImageNet, we train a no-reference regressor capable of predicting perceptual quality.
                    The proposed framework bridges full-reference supervision and no-reference inference, offering a scalable and accurate solution for FIQA in challenging conditions and paving the way for application-specific, data-driven IQA designs.
                    </p>

                <div class="publication-actions">
                    <a href="../../assets/articles/ibpria.pdf" class="button" target="_blank" >Read article</a>
                    <a href="ibpria.pdf" download class="button">Download PDF</a>
                </div>
            </article>

            <!-- Mais artigos aqui -->
        </section>
    </main>

    <footer class="site-footer container">
        <hr>
        <p>&copy; <span id="copyright"></span> André Neto</p>
        <a href="mailto:email@ags-neto.com">email@ags-neto.com</a>
    </footer>

    <script>
        async function fetchCitations(doi, elementId) {
            try {
                const res = await fetch(`https://api.semanticscholar.org/graph/v1/paper/${doi}?fields=citationCount`);
                const data = await res.json();
                document.getElementById(elementId).textContent = data.citationCount || '0';
            } catch (e) {
                document.getElementById(elementId).textContent = 'N/D';
            }
        }

        fetchCitations('DOI_DO_ARTIGO_AQUI', 'citations-artigo-1');
    </script>
</body>

</html>
